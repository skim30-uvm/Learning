{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright 2020 Google LLC. Double-click here for license information.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
    "which is a derivative work from original NIST datasets. \n",
    "MNIST dataset is made available under the terms of the \n",
    "Creative Commons Attribution-Share Alike 3.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Objectives:\n",
    "After doing this Colab, you'll know how to do the following:\n",
    "\n",
    "Understand the classic MNIST problem.\n",
    "Create a deep neural network that performs multi-class classification.\n",
    "Tune the deep neural network.\n",
    "This exercise introduces image classification with machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset\n",
    "This MNIST dataset contains a lot of examples:\n",
    "\n",
    "The MNIST training set contains 60,000 examples.\n",
    "The MNIST test set contains 10,000 examples.\n",
    "Each example contains a pixel map showing how a person wrote a digit.\n",
    "\n",
    "Each example in the MNIST dataset consists of:\n",
    "\n",
    "A label specified by a rater. Each label must be an integer from 0 to 9. For example, in the preceding image, the rater would almost certainly assign the label 1 to the example.\n",
    "A 28x28 pixel map, where each pixel is an integer between 0 and 255. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent various shades of gray.\n",
    "This is a multi-class classification problem with 10 output classes, one for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset\n",
    "tf.keras provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
    "\n",
    "Loads both the training set and the test set.\n",
    "Separates each set into features and labels.\n",
    "The relevant convenience function for MNIST is called mnist.load_data():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output example #2917 of the training set.\n",
    "x_train[2917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa8d3517b80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alternatively, you can call matplotlib.pyplot.imshow to interpret the preceding numeric array as an image.\n",
    "# Use false colors to visualize the array.\n",
    "plt.imshow(x_train[2917])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map each feature value from its current representation (an integer between 0 and 255) \n",
    "#to a floating-point value between 0 and 1.0.\n",
    "x_train_normalized = x_train / 255.0\n",
    "x_test_normalized = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "# Define the plotting function\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "    # list_of_metrics should be one of the names shown in:\n",
    "    # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create_model function defines the topography of the deep neural net, specifying the following:\n",
    "\n",
    "The number of layers in the deep neural net.\n",
    "The number of nodes in each layer.\n",
    "Any regularization layers.\n",
    "The create_model function also defines the activation function of each layer. The activation function of the output layer is softmax, which will yield 10 different outputs for each example. Each of the 10 outputs provides the probability that the input example is a certain digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate):\n",
    "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "\n",
    "    # All models in this course are sequential.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # The features are stored in a two-dimensional 28X28 array. \n",
    "    # Flatten that two-dimensional array into a a one-dimensional \n",
    "    # 784-element array.\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "    # Define the first hidden layer.   \n",
    "    model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "    \n",
    "    # Define the second hidden layer?   \n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "    # Define a dropout regularization layer. \n",
    "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    # Define the output layer. The units parameter is set to 10 because\n",
    "    # the model must choose among 10 possible output values (representing\n",
    "    # the digits from 0 to 9, inclusive).\n",
    "    #\n",
    "    # Don't change this layer.\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.  \n",
    "    # Notice that the loss function for multi-class classification\n",
    "    # is different than the loss function for binary classification.  \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    "\n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.0615 - accuracy: 0.6747 - val_loss: 0.3527 - val_accuracy: 0.8963\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3736 - accuracy: 0.8896 - val_loss: 0.2458 - val_accuracy: 0.9288\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.9232 - val_loss: 0.1878 - val_accuracy: 0.9434\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1994 - accuracy: 0.9410 - val_loss: 0.1523 - val_accuracy: 0.9544\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1657 - accuracy: 0.9504 - val_loss: 0.1346 - val_accuracy: 0.9592\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1389 - accuracy: 0.9592 - val_loss: 0.1238 - val_accuracy: 0.9637\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.1189 - accuracy: 0.9651 - val_loss: 0.1122 - val_accuracy: 0.9658\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1043 - accuracy: 0.9697 - val_loss: 0.1073 - val_accuracy: 0.9676\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0918 - accuracy: 0.9728 - val_loss: 0.1001 - val_accuracy: 0.9696\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0791 - accuracy: 0.9763 - val_loss: 0.0938 - val_accuracy: 0.9716\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 0.0915 - val_accuracy: 0.9723\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0630 - accuracy: 0.9810 - val_loss: 0.0884 - val_accuracy: 0.9743\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0573 - accuracy: 0.9834 - val_loss: 0.0853 - val_accuracy: 0.9760\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.0853 - val_accuracy: 0.9746\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0447 - accuracy: 0.9870 - val_loss: 0.0832 - val_accuracy: 0.9758\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0408 - accuracy: 0.9877 - val_loss: 0.0807 - val_accuracy: 0.9773\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0367 - accuracy: 0.9897 - val_loss: 0.0806 - val_accuracy: 0.9762\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0321 - accuracy: 0.9910 - val_loss: 0.0811 - val_accuracy: 0.9779\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0797 - val_accuracy: 0.9773\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.0832 - val_accuracy: 0.9770\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0839 - val_accuracy: 0.9768\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0831 - val_accuracy: 0.9759\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.0841 - val_accuracy: 0.9772\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0825 - val_accuracy: 0.9779\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0834 - val_accuracy: 0.9772\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0872 - val_accuracy: 0.9786\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0862 - val_accuracy: 0.9783\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0850 - val_accuracy: 0.9786\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.0849 - val_accuracy: 0.9790\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0878 - val_accuracy: 0.9787\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0884 - val_accuracy: 0.9784\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0886 - val_accuracy: 0.9787\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0884 - val_accuracy: 0.9792\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0942 - val_accuracy: 0.9785\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0918 - val_accuracy: 0.9795\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.0956 - val_accuracy: 0.9791\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0923 - val_accuracy: 0.9787\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0943 - val_accuracy: 0.9787\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.0927 - val_accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0964 - val_accuracy: 0.9797\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0999 - val_accuracy: 0.9787\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0964 - val_accuracy: 0.9791\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0981 - val_accuracy: 0.9799\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0981 - val_accuracy: 0.9794\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0966 - val_accuracy: 0.9792\n",
      "\n",
      " Evaluate the new model against the test set:\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08209041506052017, 0.9815999865531921]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
    "                           epochs, batch_size, validation_split)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
